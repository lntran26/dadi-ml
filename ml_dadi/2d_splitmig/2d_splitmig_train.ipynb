{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import dadi\n",
    "import pickle\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..')) # this is the ml_dadi dir\n",
    "import data_manip, ml_models\n",
    "from data_manip import generating_data\n",
    "from ml_models import rfr_train, mlpr_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# generate a list of theta values to run scaling and add variance\n",
    "theta_list = [1,10000,1000,100] # order of increase variance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# designate demographic model, sample size, and extrapolation grid \n",
    "func = dadi.Demographics2D.split_mig\n",
    "ns = [20,20]\n",
    "pts_l = [40, 50, 60]\n",
    "logs = [True, True, False, False]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Generate parameter list for training:\n",
    "train_params = [(nu1, nu2, T, m) for nu1 in np.linspace(-2, 2, 5)\n",
    "                            for nu2 in np.linspace(-2, 2, 5)\n",
    "                            for T in np.linspace(0.1, 2, 10)\n",
    "                            for m in np.linspace(1, 10, 10)]\n",
    "# print training set info \n",
    "print('n_samples training: ', len(train_params))\n",
    "print('Range of training params:', min(train_params), 'to', max(train_params))\n",
    "print('Theta list:', theta_list)\n",
    "# Make a list of training data dictionaries, one dictionary for each theta case\n",
    "list_train_dict = generating_data(train_params, theta_list, func, ns, pts_l, logs)\n",
    "pickle.dump(list_train_dict, open('data/new_func/train_data', 'wb'), 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_samples training:  2500\n",
      "Range of training params: (-2.0, -2.0, 0.1, 1.0) to (2.0, 2.0, 2.0, 10.0)\n",
      "Theta list: [1, 10000, 1000, 100]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load datasets for training\n",
    "list_train_dict = pickle.load(open('data/new_func/train_data','rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Train RFR and save the list of trained RFR into pickle file\n",
    "list_rfr = [rfr_train(train_dict) for train_dict in list_train_dict]\n",
    "pickle.dump(list_rfr, open('data/new_func/list_rfr', 'wb'), 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Train MLPR and save the list of trained MLPR into pickle file\n",
    "list_mlpr = [mlpr_train(train_dict, max_iter=1000) \n",
    "                for train_dict in list_train_dict]\n",
    "pickle.dump(list_mlpr, open('data/new_func/list_mlpr', 'wb'), 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Generate Test Datasets\n",
    "test_params = []\n",
    "for i in range(100):\n",
    "    nu1 = random.random() * 4 - 2\n",
    "    nu2 = random.random() * 4 - 2\n",
    "    T = random.random() * 1.9 + 0.1\n",
    "    m = random.random() * 9 + 1\n",
    "    params = (nu1, nu2, T, m)\n",
    "    test_params.append(params)\n",
    "# print testing set info \n",
    "print('n_samples testing: ', len(test_params))\n",
    "print('Range of testing params:', min(test_params), 'to', max(test_params))\n",
    "print('Theta list:', theta_list)\n",
    "# Make a list of test data dictionaries, one dictionary for each theta case\n",
    "list_test_dict = generating_data(test_params, theta_list, func, ns, pts_l, logs)\n",
    "# Save testing set as a pickle file\n",
    "pickle.dump(list_test_dict, open('data/new_func/test_data', 'wb'), 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_samples testing:  200\n",
      "Range of testing params: (-1.9975195534627979, 0.2677594022856864, 1.9745935510695751, 5.71439269421244) to (1.996530658159866, 0.848968117511478, 1.5548772787189087, 7.899324008073518)\n",
      "Theta list: [1, 10000, 1000, 100]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55a74aeb62132f0f3c0e21cb55598b2507f2ee10a4f6ed821cc7086dc4f1d0ba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}