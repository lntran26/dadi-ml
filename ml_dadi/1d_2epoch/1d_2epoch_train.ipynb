{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "import dadi, random, pickle\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..')) # this is the ml_dadi dir\n",
    "import data_manip, ml_models\n",
    "from data_manip import generating_data\n",
    "from ml_models import rfr_train, mlpr_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# generate a list of theta values to run scaling and add variance\n",
    "theta_list = [1,10000,1000,100] # order of increase variance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# designate demographic model, sample size, and extrapolation grid \n",
    "func = dadi.Demographics1D.two_epoch\n",
    "ns = [20]\n",
    "pts_l = [40, 50, 60]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# designate which param to be in log scale\n",
    "logs = [True, False]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# # Generate parameter list for training: exclude params where T/nu > 5 version\n",
    "# # using log scale for nu\n",
    "# train_params = [(nu,T) for nu in np.linspace(-2, 2, 25)\n",
    "#                       for T in np.linspace(0.1, 2, 24) if T/10**nu <= 5]\n",
    "# # print training set info \n",
    "# print('n_samples training: ', len(train_params))\n",
    "# print('Range of training params:', min(train_params), 'to', max(train_params))\n",
    "# print('Theta list:', theta_list)\n",
    "# # Make a list of training data dictionaries, one dictionary for each theta case\n",
    "# list_train_dict=generating_data(train_params, theta_list, func, ns, pts_l, logs)\n",
    "# pickle.dump(list_train_dict, open('data/new_func/train_data', 'wb'), 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_samples training:  410\n",
      "Range of training params: (-1.6666666666666667, 0.1) to (2.0, 2.0)\n",
      "Theta list: [1, 10000, 1000, 100]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load new datasets for training\n",
    "list_train_dict = pickle.load(open('data/new_func/train_data','rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Train RFR \n",
    "list_rfr = [rfr_train(train_dict) for train_dict in list_train_dict]\n",
    "pickle.dump(list_rfr, open('data/new_func/list_rfr', 'wb'), 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Train MLPR with adam solver (default)\n",
    "list_mlpr_adam = [mlpr_train(train_dict, max_iter=500) \n",
    "                        for train_dict in list_train_dict]\n",
    "pickle.dump(list_mlpr_adam, open('data/new_func/list_mlpr_adam', 'wb'), 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Train MLPR with lbfgs solver\n",
    "# Need large max_iter and take longer to run but perform the best for two_epoch\n",
    "list_mlpr_lbfgs = [mlpr_train(train_dict, solver='lbfgs', max_iter=5000)\n",
    "                        for train_dict in list_train_dict]\n",
    "pickle.dump(list_mlpr_lbfgs, open('data/new_func/list_mlpr_lbfgs', 'wb'), 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Generate Test Datasets\n",
    "test_params = []\n",
    "while len(test_params) < 100: \n",
    "# generate random nu and T within the same range as training data range\n",
    "    nu = random.random() * 4 - 2 # nu in log scale\n",
    "    T = random.random() * 1.9 + 0.1\n",
    "    # exclude T/nu > 5\n",
    "    if T/10**nu <= 5:\n",
    "        params = (nu, T)\n",
    "        test_params.append(params)\n",
    "# print testing set info \n",
    "print('n_samples testing: ', len(test_params))\n",
    "print('Range of testing params:', min(test_params), 'to', max(test_params))\n",
    "print('Theta list:', theta_list)\n",
    "# Make a list of test data dictionaries, one dictionary for each theta case\n",
    "list_test_dict = generating_data(test_params, theta_list, func, ns, pts_l, logs)\n",
    "# Save testing set as a pickle file\n",
    "pickle.dump(list_test_dict, open('data/new_func/test_data', 'wb'), 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_samples testing:  100\n",
      "Range of testing params: (-1.2835012041008178, 0.15754354169567486) to (1.9973742028068813, 0.7008000830008293)\n",
      "Theta list: [1, 10000, 1000, 100]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Generate Test Datasets Full Range\n",
    "test_params = []\n",
    "while len(test_params) < 100: \n",
    "# generate random nu and T within the same range as training data range\n",
    "    nu = random.random() * 4 - 2 # nu in log scale\n",
    "    T = random.random() * 1.9 + 0.1\n",
    "    # # exclude T/nu > 5\n",
    "    # if T/10**nu <= 5:\n",
    "    #     params = (nu, T)\n",
    "    #     test_params.append(params)\n",
    "    test_params.append((nu, T))\n",
    "\n",
    "# print testing set info \n",
    "print('n_samples testing: ', len(test_params))\n",
    "print('Range of testing params:', min(test_params), 'to', max(test_params))\n",
    "print('Theta list:', theta_list)\n",
    "# Make a list of test data dictionaries, one dictionary for each theta case\n",
    "list_test_dict = generating_data(test_params, theta_list, func, ns, pts_l, logs)\n",
    "# Save testing set as a pickle file\n",
    "pickle.dump(list_test_dict, open('data/new_func/test_data_full', 'wb'), 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_samples testing:  100\n",
      "Range of testing params: (-1.9835824785940854, 1.169385319983439) to (1.9724244058327387, 1.7354305216161359)\n",
      "Theta list: [1, 10000, 1000, 100]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55a74aeb62132f0f3c0e21cb55598b2507f2ee10a4f6ed821cc7086dc4f1d0ba"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}